
<!DOCTYPE html>
<html>

<body>
<div id="container"><h1 class="h1"><span class="span">Bayesian Inference</span></h1><h2 class="h2"><span class="span">Homework</span></h2><img class="image" src="graphs/31_hw.png"><p class="paragraph"><span class="span">Have:</span></p><p class="mathmultiline">$$
    (P(J \mid G) = P(J \mid G, I))
    \implies G \dbot I \mid G
    \\
    (P(M \mid G, B, I) = P(M, G, B, I, J))
    \implies M \dbot J \mid G, B, I
$$</p><p class="paragraph"><span class="span">Some expansions:</span></p><p class="mathmultiline">$$
\begin{aligned}
    P(b, i, \lnot m, g, j)
    &= P(b) P(\lnot m) P(i \mid b, \lnot m) P(g \mid b, i, \lnot m) P(j \mid g)
    \\
    P(j \mid b, i, m)
    &= \frac{P(j, b, i, m)}{P(b, i, m)}
\end{aligned}
$$</p><p class="paragraph"><span class="span">The total expansion:</span></p><p class="mathmultiline">$$
    P(j, b, i, m)
    &= \sum_g P(g, j, b, i, m) \\
    &= \sum_g P(b) P(b) P(i \mid b, m) P(g, b, i, m) P(j, g) \\
    &= P(b) P(m) P(i \mid b, m) \sum_g P(g \mid b, i, m) P(j, g) \\
    &= P(b) P(m) P(i \mid b, m) h_1(b, i, m, j)
    \\
    P(b, i, m)
    &= \sum_j \sum_g P(j, g, b, i, m) \\
    &= \sum_j \sum_g P(b) P(m) P(i \mid b, m) P(g \mid b, i, m) P(j \mid g) \\
    &= \sum_g P(b) P(m) P(i \mid b, m) P(g \mid b, i, m) (\sum_j P(j \mid g) = 1) \\
    &= P(b) P(m) P(i \mid b, m) (\sum_g P(g \mid b, i, m) = 1) \\
    &= h_1(b, i, m, j)
$$</p><p class="paragraph"><span class="span">What is the time complexity of this variable elimination process? We can predict this via looking at the graph.</span></p><p class="paragraph"><span class="span">Consider</span></p><p class="mathmultiline">$$
    P(j)
    &= \sum_b \sum_i \sum_m \sum_j P(b) P(m) P(i \mid b, m) P(g \mid b, i, m) P(j \midg) \\
    &= \sum_b \sum_m \sum_j P(b) P(m) P(j \midg)
        (h_1(b, m, g) := \sum_i P(g \mid b, i, m) P(i \mid b, m)) \\
$$</p><p class="paragraph"><span class="span">Then, we need to compute <span class="mathinline">\(h_1(b, m, g)\)</span> for all values of <span class="mathinline">\(b, m, g\)</span>, and inside, <span class="mathinline">\(i\)</span>. This is <span class="mathinline">\(|I| \cdot |B| \cdot |M| \cdot |G|\)</span>. Graphically,</span></p><img class="image" src="graphs/30_hw01.png"><p class="paragraph"><span class="span">This is the "moral graph", where nodes that appear in the same probability expression are connected. For example, B and M are connected since we have <span class="mathinline">\(P(i \mid b, m)\)</span> in <span class="mathinline">\(P(j)\)</span> (above).</span></p><p class="paragraph"><span class="span">If each variable has <span class="mathinline">\(d\)</span> possible values, then <span class="mathinline">\(h(x_i, \dots, x_w)\)</span> runs in <span class="mathinline">\(O(d^{w+1})\)</span>, and we need to do this <span class="mathinline">\(n\)</span> times where <span class="mathinline">\(n\)</span> is the number of such <span class="mathinline">\(h\)</span> functions we expand to, taking a total of <span class="mathinline">\(O(n d^{w+1})\)</span> time. The process of these <span class="mathinline">\(h\)</span>'s eliminating variables is demonstrated graphically:</span></p><img class="image" src="graphs/30_hw01.png"><p class="paragraph"><span class="span"><span class="mathinline">\(\downarrow\)</span></span></p><img class="image" src="graphs/30_hw01.png"><p class="paragraph"><span class="span"><span class="mathinline">\(\downarrow\)</span></span></p><img class="image" src="graphs/30_hw01.png"><p class="paragraph"><span class="span">Each graph has a <span class="bold">maximum clique size</span>. This is the number of <span class="mathinline">\(h\)</span>'s we'll need to emilinate the graph's varaibles.</span></p><h2 class="h2"><span class="span">Hidden Markov Model (HMM)</span></h2><p class="paragraph"><span class="span">We setup a Bayesian Network like</span></p><h3 class="h3"><span class="span">Example Good</span></h3><img class="image" src="graphs/31_hmm01.png"><p class="paragraph"><span class="span">Where the <span class="mathinline">\(H_i\)</span> are the <span class="bold">hidden states</span>, and the <span class="mathinline">\(O_i\)</span> are the <span class="bold">observations</span>. We want to find:</span></p><p class="mathmultiline">$$
    P(H_1, \dots, H_k \mid O_1, \dots, O_k)
$$</p><p class="paragraph"><span class="span">How long does is take to calculate this? The maximum clique size is 2, so it will take <span class="mathinline">\(2 d^{w+1}\)</span>.</span></p><h3 class="h3"><span class="span">Example Bad</span></h3><img class="image" src="graphs/31_hmm02.png"><p class="paragraph"><span class="span">This one actually has a nice path <span class="mathinline">\(X_{21} \rightarrow X_{12} \rightarrow X_{13} \rightarrow X_{23} \rightarrow X_{32} \rightarrow X_{31} \rightarrow X_{21}\)</span>.</span></p></div></body>

<head><link rel="stylesheet" type="text/css" href="style/main.css">
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-MML-AM_CHTML" async></script>
<script type="text/javascript" src="highlight/highlight.pack.js">
</script><script type="text/javascript">hljs.initHighlightingOnLoad()</script></head>

</html>
