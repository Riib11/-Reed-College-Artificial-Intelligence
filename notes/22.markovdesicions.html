
<!DOCTYPE html>
<html>

<body>
<div id="container"><h1 class="h1"><span class="span">Markov Desicions</span></h1><p class="mathmultiline">$$
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\p}{^\prime}
$$</p><p class="paragraph"><span class="span"><span class="italic">Definition</span>. A <span class="bold">MDP</span> is a triple <span class="mathinline">\((M,R,w)\)</span> where</span></p><li class="unorderedlistitem"><span class="span"><span class="mathinline">\(M = (Q, \Sigma, \Delta, q_0, F)\)</span> is a state machine</span></li><li class="unorderedlistitem"><span class="span"><span class="mathinline">\(R : Q \times \N \rightarrow \R\)</span> is a <span class="italic">reward function</span>.</span></li><li class="unorderedlistitem"><span class="span"><span class="mathinline">\(w : \Delta \rightarrow \R\)</span> such that <span class="mathinline">\(\forall q \in Q : \forall \sigma \in \Sigma : \sum_{(q, \sigma, q\p)} w((q, \sigma, q\p)) = 1\)</span></span></li><p class="paragraph"><span class="span">Review of shorthand:</span></p><li class="unorderedlistitem"><span class="span"><span class="mathinline">\(\forall t \geq 0 : R_t(q) := R(q,t)\)</span></span></li><li class="unorderedlistitem"><span class="span"><span class="mathinline">\(\forall \langle q, \sigma, q\p \rangle \in \Delta : P(q\p \mid q, \sigma) := w(\langle q, \sigma, q\p \rangle)\)</span></span></li><li class="unorderedlistitem"><span class="span"><span class="mathinline">\(q \xrightarrow{\sigma_0} q_1 \xrightarrow{\sigma_1} q_2 \rightarrow \cdots := \langle (q,\sigma_0,q_1), (q_1, \sigma_1, q_2), \dots \rangle\)</span></span></li><li class="unorderedlistitem"><span class="span"><span class="mathinline">\(\text{reward}(q \xrightarrow{\sigma_0} q_1 \xrightarrow{\sigma_1} q_2 \rightarrow \cdots \xrightarrow{\sigma_{n-1}} q_n) = \sum_{i} R_i(q_i)\)</span></span></li><li class="unorderedlistitem"><span class="span">the above goes to <span class="mathinline">\(P(q \xrightarrow{\sigma_0} q_1 \xrightarrow{\sigma_1} q_2 \rightarrow \cdots \xrightarrow{\sigma_{n-1}} q_n) = P(q_1 \mid q, \sigma_0) \cdot P(q_2 \mid q_1, \sigma_1) \cdots P(q_n \mid q_{n-1}, \sigma_{n-1})\)</span>.</span></li><h2 class="h2"><span class="span">Blackjack</span></h2><p class="paragraph"><span class="span"><span class="italic">Definition</span>. A <span class="bold">policy</span> is a mapping from states to actions.</span></p><p class="paragraph"><span class="span">For policy <span class="mathinline">\(\pi\)</span></span></p><p class="mathmultiline">$$
\begin{aligned}
    U(A20)
    &= \text{reward}(A20 \xrightarrow{H} S21)
        P(A20 \xrightarrow{H} S21) +
        \text{reward}(A20 \xrightarrow{H} \text{Bust})
        P(A20 \xrightarrow{H} \text{Bust}) \\
    &= [R_0(A20) + R_1(S21)] P(A20 \xrightarrow{H} S21) +
        [R_0(A20) + R_1(\text{Bust})] P(A20 \xrightarrow{H} \text{Bust}) \\
    &= R_0(A20)[P(A20 \xrightarrow{H} S21) + P(A20 \xrightarrow{H} \text{Bust})] +
        R(S21) P(A20 \xrightarrow{H} S21) +
        R(\text{Bust}) P(A20 \xrightarrow{H} \text{Bust}) \\
    &= R_0(A20) + \gamma R_0(S21) P(A20 \xrightarrow{H} S21) +
        \gamma R_0 (\text{Bust}) P(A20 \xrightarrow{H} \text{Bust})\\
    &= \dots \\
    &= R_0(A20) + \gamma \sum_{q\p \in Q} U^\pi(q\p) P(q\p \mid A20, \text{Hit})
\end{aligned}
$$</p></div></body>

<head><link rel="stylesheet" type="text/css" href="style/main.css">
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-MML-AM_CHTML" async></script>
<script type="text/javascript" src="highlight/highlight.pack.js">
</script><script type="text/javascript">hljs.initHighlightingOnLoad()</script></head>

</html>
